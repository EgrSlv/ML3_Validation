{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "228f2262",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Chapter V. Task**\n",
    "\n",
    "We will continue our training with a problem from Kaggle.com. \n",
    "In this chapter, we will implement all the validation schemes, some hyperparameter tuning methods, and feature selection methods described above. Measure quality metrics on training and test samples. Will detect overfitted models and regularize them. And dive deeper with native model estimation and comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f5fef",
   "metadata": {},
   "source": [
    "### 1. **Answer the questions from the introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c16cf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### a. What is leave-one-out? Provide limitations and strengths.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd72f3d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Leave-One-Out кросс валидация - это частный случай k-fold Cross Validation, где k = n. Данные размерности 10 делятся на обучающую и тестовую выборки по принципу 9 обучающей и 1 тестовая на каждой итерации для всех данных. При этом,каждый набор данных __ровно один раз__ становится тестовым (см. пример кода.). Другими словами, для **_n_** образцов мы имеем **_n-1_** тренировочных данных и **1** тестовый набор.\n",
    "Достоинства:\n",
    " * максимальное использование данных для обучения\n",
    " * не зависит от случайного разбиения\n",
    " * эффективен только на маленьких наборах данных\n",
    "\n",
    "Недостатки:\n",
    " * высокая стоимость вычислительных операций для больших выборок данных - O(n)\n",
    " * высокая дисперсия оценки\n",
    " * может недооценивать ошибку на новых данных\n",
    " * имеет нестабильную оценку\n",
    "\n",
    "```Python\n",
    ">>> from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    ">>> X = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    ">>> loo = LeaveOneOut()\n",
    ">>> for train, test in loo.split(X):\n",
    "...     print(\"%s %s\" % (train, test))\n",
    "\n",
    "[1 2 3 4 5 6 7 8 9] [0]\n",
    "[0 2 3 4 5 6 7 8 9] [1]\n",
    "[0 1 3 4 5 6 7 8 9] [2]\n",
    "[0 1 2 4 5 6 7 8 9] [3]\n",
    "[0 1 2 3 5 6 7 8 9] [4]\n",
    "[0 1 2 3 4 6 7 8 9] [5]\n",
    "[0 1 2 3 4 5 7 8 9] [6]\n",
    "[0 1 2 3 4 5 6 8 9] [7]\n",
    "[0 1 2 3 4 5 6 7 9] [8]\n",
    "[0 1 2 3 4 5 6 7 8] [9]\n",
    "```\n",
    "\n",
    "Источник: https://scikit-learn.org/stable/modules/cross_validation.html#leave-one-out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb16e96",
   "metadata": {},
   "source": [
    "#### b. How do Grid Search, Randomized Grid Search, and Bayesian optimization work?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc7c9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = {1, 2, 3, 4, 5}\n",
    "B = {6, 7, 8, 9}\n",
    "C = {10, 11, 12}\n",
    "\n",
    "def cartesian_product(*sets):\n",
    "    \"\"\"\n",
    "    Декартово произведение множеств\n",
    "    \"\"\"\n",
    "    result = [[]]\n",
    "    for pool in sets:\n",
    "        result = [x + [y] for x in result for y in pool]\n",
    "    return [tuple(item) for item in result]\n",
    "\n",
    "decart = cartesian_product(A, B, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c342136f",
   "metadata": {},
   "source": [
    "> Этапы работы поиска наилучших гиперпараметров через Grid Search:\n",
    " 1. **Определение пространства внешних гиперпараметров**. На первом этапе необходимо обозначить какие гиперпараметры мы ищем. Параметр должен содержать множество значений, по которым мы будем проводить поиск. Параметров может быть несколько. Несколько параметров собираются в единый словарь, где ключи — имена гиперпараметров, а значения — списки возможных значений для каждого параметра.\n",
    " 2. **Создание сетки гиперпараметров**. Создается декартово произведение всех списков значений, получая полный набор всех возможных комбинаций гиперпараметров.\n",
    " 3. **Проход по списку гиперпараметров**. Алгоритм GridSearch последовательно проходит по каждой комбинации гиперпараметров, обучается и оценивается с помощью k-fold CV, вычисляется средняя оценка гиперпараметров по всем фолдам для заданной метрики.\n",
    " 4. **Сохранение и возвращение результата**. По окончании подбора параметров выбирается комбинация с наилучшей средней оценкой. GridSearch возвращает: лучшие гиперпараметры `best_params_`; лучшие оценки `best_score_`; полную информацию по всем комбинациям `cv_results_`.\n",
    "\n",
    "> Randomized Grid Search:\n",
    " * Принцип работы Randomized Grid Search схож с работой Grid Search, но не создает полную сетку всех комбинаций гиперпараметров. Вместо этого поиск происходит случайным образом. Еще одно отличие - это наличие итераций. На каждой итерации `n_iter` случайным образом генерируется комбинация гиперпараметров, происходит обучение модели и оценка её качества с помощью k-fold CV на всех фолдах. Случайный выбор позволяет ускорить процесс подбора гиперпараметров. В таком случае, гиперпараметры следует задавать не только дискретным образом, но и в диапазоне и\\или распределении, например: `stats.uniform(0.1, 10)`, здесь будет создано распределение случайных чисел от 0.1 до 10 + 0.1. Случайное число из данного распределения будет получено внутри GridSearch.\n",
    "\n",
    "> Bayesian optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa1c8d",
   "metadata": {},
   "source": [
    "#### c. Explain classification of feature selection methods. Explain how Pearson and Chi2 work. Explain how Lasso works. Explain what permutation significance is. Become familiar with SHAP.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b373400e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "095d59ab",
   "metadata": {},
   "source": [
    "### **2. Introduction — do all the preprocessing from the previous lesson**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c3476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daecaf5",
   "metadata": {},
   "source": [
    "#### a. Read all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b5df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.a\n",
    "df = pd.concat(\n",
    "    [\n",
    "        pd.read_json(\"../datasets/train.json\", convert_dates=[\"created\"]),\n",
    "        # pd.read_json(\"../datasets/test.json\", convert_dates=[\"created\"])\n",
    "    ]\n",
    ").reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1dfd6b",
   "metadata": {},
   "source": [
    "#### b. Create features: 'Elevator', 'HardwoodFloors', 'CatsAllowed', 'DogsAllowed', 'Doorman', 'Dishwasher', 'NoFee', 'LaundryinBuilding', 'FitnessCenter', 'Pre-War', 'LaundryinUnit', 'RoofDeck', 'OutdoorSpace', 'DiningRoom', 'HighSpeedInternet', 'Balcony', 'SwimmingPool', 'LaundryInBuilding', 'NewConstruction', 'Terrace'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ebdd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.b\n",
    "pattern = re.compile(r\"[\\[\\]\\'\\\"\\s]\")\n",
    "remove_sym = (lambda x: list([re.sub(pattern, '', elem) for elem in x]))\n",
    "df[\"features\"] = df[\"features\"].apply(remove_sym)\n",
    "\n",
    "target = [\"price\"]\n",
    "rooms = [\"bedrooms\", \"bathrooms\"]\n",
    "features = ['Elevator', 'HardwoodFloors', 'CatsAllowed', 'DogsAllowed',\n",
    "            'Doorman', 'Dishwasher', 'NoFee', 'LaundryinBuilding',\n",
    "            'FitnessCenter', 'Pre-War', 'LaundryinUnit', 'RoofDeck',\n",
    "            'OutdoorSpace', 'DiningRoom', 'HighSpeedInternet', 'Balcony',\n",
    "            'SwimmingPool', 'LaundryInBuilding', 'NewConstruction', 'Terrace',]\n",
    "for feature in features:\n",
    "    df[feature] = (\n",
    "        df[\"features\"]\n",
    "        .apply(lambda x: 1 if feature in x else 0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25651014",
   "metadata": {},
   "source": [
    "### 3. **Implement the next methods:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7006ca",
   "metadata": {},
   "source": [
    "#### a. Split data into 2 parts randomly with parameter test_size (ratio from 0 to 1), return training and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b66524c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of the samples is identical: True \n",
      "Sample sizes: train(39481, 35), test(9871, 35) \n",
      "There are no intersections: True\n"
     ]
    }
   ],
   "source": [
    "# 3.a\n",
    "def my_train_test_split(X, y, test_size=0.25, random_state=None, shuffle=True):\n",
    "    random = np.random.RandomState(random_state)\n",
    "    if np.array_equal(X.index.to_numpy(), y.index.to_numpy()) is False:\n",
    "        raise ValueError(\"Indices of 'X' and 'y' must be equal\")\n",
    "\n",
    "    n = len(X)\n",
    "    if isinstance(test_size, int):\n",
    "        if test_size <= 0 or test_size >= n:\n",
    "            raise ValueError(\"'test_size' must be between 1 and len(X)-1\")\n",
    "    elif isinstance(test_size, float):\n",
    "        if test_size <= 0.0 or test_size >= 1.0:\n",
    "            raise ValueError(\"'test_size' must be between 0.0 and 1.0\")\n",
    "        test_size = ceil(n * test_size)\n",
    "    else:\n",
    "        raise ValueError(\"'test_size' must be float or int\")\n",
    "\n",
    "    idx = X.index.to_numpy()\n",
    "    if shuffle:\n",
    "        random = np.random.RandomState(random_state)\n",
    "        idx = random.permutation(idx)\n",
    "\n",
    "    train_idxs = idx[test_size:]\n",
    "    test_idxs = idx[:test_size]\n",
    "\n",
    "    return (pd.concat([X.loc[train_idxs], y.loc[train_idxs]], axis=1),\n",
    "            pd.concat([X.loc[test_idxs], y.loc[test_idxs]], axis=1))\n",
    "\n",
    "\n",
    "train, test = my_train_test_split(\n",
    "    df.drop(columns=target),\n",
    "    df[target],\n",
    "    test_size=0.2\n",
    ")\n",
    "train_idx, test_idx = train.index, test.index\n",
    "print(\n",
    "    \"The sum of the samples is identical: \" +\n",
    "    f\"{train.shape[0] + test.shape[0] == len(df)}\",\n",
    "    \"\\nSample sizes: \" +\n",
    "    f\"train{train.shape}, test{test.shape}\",\n",
    "    \"\\nThere are no intersections:\", all([train_idx.intersection(test_idx).empty,\n",
    "                                          test_idx.intersection(train_idx).empty])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba02c8cb",
   "metadata": {},
   "source": [
    "#### b. Randomly split data into 3 parts with parameters validation_size and test_size, return train, validation and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e14674e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of the samples is identical: True \n",
      "Sample sizes: train(29610, 35), validation(9871, 35), test(9871, 35) \n",
      "There are no intersections: True\n"
     ]
    }
   ],
   "source": [
    "# 3.b\n",
    "def my_train_validation_test_split(X,\n",
    "                                   y,\n",
    "                                   validation_size=0.25,\n",
    "                                   test_size=0.25,\n",
    "                                   random_state=None,\n",
    "                                   shuffle=True):\n",
    "    random = np.random.RandomState(random_state)\n",
    "    if np.array_equal(X.index.to_numpy(), y.index.to_numpy()) is False:\n",
    "        raise ValueError(\"Indices of 'X' and 'y' must be equal\")\n",
    "\n",
    "    n = len(X)\n",
    "    if isinstance(test_size, int) and isinstance(validation_size, int):\n",
    "        if test_size <= 0 or test_size >= n:\n",
    "            raise ValueError(\"'test_size' must be between 1 and len(X)-1\")\n",
    "        if validation_size <= 0 or validation_size >= n:\n",
    "            raise ValueError(\"'validation_size' must be between 1 and len(X)-1\")\n",
    "    elif isinstance(test_size, float) and isinstance(validation_size, float):\n",
    "        if test_size <= 0.0 or test_size >= 1.0:\n",
    "            raise ValueError(\"'test_size' must be between 0.0 and 1.0\")\n",
    "        if validation_size <= 0.0 or validation_size >= 1.0:\n",
    "            raise ValueError(\"'validation_size' must be between 0.0 and 1.0\")\n",
    "        if test_size + validation_size >= 1:\n",
    "            raise ValueError(\"test_size + validation_size must be < 1\")\n",
    "        test_size = ceil(n * test_size)\n",
    "        validation_size = ceil(n * validation_size)\n",
    "    else:\n",
    "        raise ValueError(\"'test_size'/'validation_size' must be float or int\")\n",
    "    if test_size + validation_size >= n:\n",
    "        raise ValueError(\"test_size + validation_size must be < len(X)\")\n",
    "\n",
    "    idx = X.index.to_numpy()\n",
    "    if shuffle:\n",
    "        random = np.random.RandomState(random_state)\n",
    "        idx = random.permutation(idx)\n",
    "    train_idxs = idx[test_size + validation_size:]\n",
    "    test_idxs = idx[:test_size]\n",
    "    validation_idxs = idx[test_size:test_size + validation_size]\n",
    "\n",
    "    return (pd.concat([X.loc[train_idxs], y.loc[train_idxs]], axis=1),\n",
    "            pd.concat([X.loc[validation_idxs], y.loc[validation_idxs]], axis=1),\n",
    "            pd.concat([X.loc[test_idxs], y.loc[test_idxs]], axis=1))\n",
    "\n",
    "\n",
    "train, validation, test = my_train_validation_test_split(\n",
    "    df.drop(columns=target),\n",
    "    df[target],\n",
    "    validation_size=0.2,\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "train_idx, validation_idx, test_idx = train.index, validation.index, test.index\n",
    "print(\n",
    "    \"The sum of the samples is identical: \" +\n",
    "    f\"{train.shape[0]+validation.shape[0]+test.shape[0] == len(df)}\",\n",
    "    \"\\nSample sizes: \"\n",
    "    f\"train{train.shape}, validation{validation.shape}, test{test.shape}\",\n",
    "    \"\\nThere are no intersections:\", all([train_idx.intersection(validation_idx).empty,\n",
    "                                          train_idx.intersection(test_idx).empty,\n",
    "                                          validation_idx.intersection(test_idx).empty,\n",
    "                                          test_idx.intersection(train_idx).empty])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9411783f",
   "metadata": {},
   "source": [
    "#### c. Split data into 2 parts with parameter date_split, return train and test samples split by date_split param."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11634a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of the samples is identical: True \n",
      "Sample sizes: train(41544, 35), test(7808, 35) \n",
      "There are no intersections: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-04-01 22:12:41')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-06-15 23:53:14')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-06-16 00:45:59')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-06-29 21:41:47')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.c\n",
    "def my_date_train_test_split(X, y, date_split=None, random_state=None, shuffle=True):\n",
    "    if np.array_equal(X.index.to_numpy(), y.index.to_numpy()) is False:\n",
    "        raise ValueError(\"Indices of 'X' and 'y' must be equal\")\n",
    "    if date_split is None:\n",
    "        raise ValueError(\"'date_split' must be provided\")\n",
    "\n",
    "    dt_cols = X.select_dtypes(include=[\"datetime\"]).columns\n",
    "    if dt_cols.empty:\n",
    "        raise ValueError(\"X does not contain a timestamp column\")\n",
    "\n",
    "    date_split = pd.to_datetime(date_split)\n",
    "    if not (date_split.date() == X[dt_cols[0]].dt.date).any():\n",
    "        raise ValueError(\n",
    "            f\"'{date_split}' is not contained in the column '{dt_cols[0]}'\"\n",
    "        )\n",
    "    X = X.sort_values(by=dt_cols[0])\n",
    "    y = y.loc[X.index]\n",
    "    train_idx = X[X[dt_cols[0]] < date_split].index.to_numpy()\n",
    "    test_idx = X[X[dt_cols[0]] >= date_split].index.to_numpy()\n",
    "\n",
    "    if shuffle:\n",
    "        random = np.random.RandomState(random_state)\n",
    "        train_idx = random.permutation(train_idx)\n",
    "        test_idx = random.permutation(test_idx)\n",
    "\n",
    "    return (pd.concat([X.loc[train_idx], y.loc[train_idx]], axis=1),\n",
    "            pd.concat([X.loc[test_idx], y.loc[test_idx]], axis=1))\n",
    "\n",
    "\n",
    "train, test = my_date_train_test_split(\n",
    "    df.drop(columns=target),\n",
    "    df[target],\n",
    "    date_split=\"2016-06-16\",\n",
    ")\n",
    "train_idx, test_idx = train.index, test.index\n",
    "print(\n",
    "    \"The sum of the samples is identical: \" +\n",
    "    f\"{train.shape[0] + test.shape[0] == len(df)}\",\n",
    "    \"\\nSample sizes: \" +\n",
    "    f\"train{train.shape}, test{test.shape}\",\n",
    "    \"\\nThere are no intersections:\", all([train_idx.intersection(test_idx).empty,\n",
    "                                          test_idx.intersection(train_idx).empty])\n",
    ")\n",
    "display(\n",
    "    train['created'].min(),\n",
    "    train['created'].max(),\n",
    "    test['created'].min(),\n",
    "    test['created'].max(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71721642",
   "metadata": {},
   "source": [
    "#### d. Split data into 3 parts with parameters validation_date and test_date, return train, validation and test samples split by input params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23a619f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of the samples is identical: True \n",
      "Sample sizes: train(16411, 35), validation(15797, 35), test(17144, 35) \n",
      "There are no intersections: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-04-01 22:12:41')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-04-30 19:21:03')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-05-01 22:36:52')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-05-31 23:10:48')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-06-01 01:10:37')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-06-29 21:41:47')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.d\n",
    "def my_date_train_validation_test_split(X,\n",
    "                                        y,\n",
    "                                        validation_date=None,\n",
    "                                        test_date=None,\n",
    "                                        random_state=None,\n",
    "                                        shuffle=True):\n",
    "    if np.array_equal(X.index.to_numpy(), y.index.to_numpy()) is False:\n",
    "        raise ValueError(\"Indices of 'X' and 'y' must be equal\")\n",
    "    if test_date is None:\n",
    "        raise ValueError(\"'test_date' must be provided\")\n",
    "    if validation_date is None:\n",
    "        raise ValueError(\"'validation_date' must be provided\")\n",
    "\n",
    "    dt_cols = X.select_dtypes(include=[\"datetime\"]).columns\n",
    "    if dt_cols.empty:\n",
    "        raise ValueError(\"X does not contain a timestamp column\")\n",
    "\n",
    "    test_date = pd.to_datetime(test_date)\n",
    "    if not (test_date.date() == X[dt_cols[0]].dt.date).any():\n",
    "        raise ValueError(\n",
    "            f\"'{test_date}' is not contained in the column '{dt_cols[0]}'\"\n",
    "        )\n",
    "\n",
    "    validation_date = pd.to_datetime(validation_date)\n",
    "    if not (validation_date.date() == X[dt_cols[0]].dt.date).any():\n",
    "        raise ValueError(\n",
    "            f\"'{validation_date}' is not contained in the column '{dt_cols[0]}'\"\n",
    "        )\n",
    "    if validation_date == test_date:\n",
    "        raise ValueError(\n",
    "            \"'validation_date' and 'test_date' must be different\"\n",
    "        )\n",
    "    if validation_date > test_date:\n",
    "        raise ValueError(\n",
    "            \"'validation_date' must be less than 'test_date'\"\n",
    "        )\n",
    "    train_idx = X[X[dt_cols[0]] < validation_date].index.to_numpy()\n",
    "    valid_idx = X[(X[dt_cols[0]] >= validation_date) &\n",
    "                  ((X[dt_cols[0]] < test_date))].index.to_numpy()\n",
    "    test_idx = X[X[dt_cols[0]] >= test_date].index.to_numpy()\n",
    "    if shuffle:\n",
    "        random = np.random.RandomState(random_state)\n",
    "        train_idx = random.permutation(train_idx)\n",
    "        valid_idx = random.permutation(valid_idx)\n",
    "        test_idx = random.permutation(test_idx)\n",
    "\n",
    "\n",
    "    return (pd.concat([X.loc[train_idx], y.loc[train_idx]], axis=1),\n",
    "            pd.concat([X.loc[valid_idx], y.loc[valid_idx]], axis=1),\n",
    "            pd.concat([X.loc[test_idx], y.loc[test_idx]], axis=1))\n",
    "\n",
    "\n",
    "train, validation, test = my_date_train_validation_test_split(\n",
    "    df.drop(columns=target),\n",
    "    df[target],\n",
    "    validation_date=\"2016-05-01\",\n",
    "    test_date=\"2016-06-01\",\n",
    "    # random_state=21,\n",
    ")\n",
    "train_idx, test_idx = train.index, test.index\n",
    "print(\n",
    "    \"The sum of the samples is identical: \" +\n",
    "    f\"{train.shape[0] + validation.shape[0] + test.shape[0] == len(df)}\",\n",
    "    \"\\nSample sizes: \" +\n",
    "    f\"train{train.shape}, validation{validation.shape}, test{test.shape}\",\n",
    "    \"\\nThere are no intersections:\", all([train_idx.intersection(test_idx).empty,\n",
    "                                          test_idx.intersection(train_idx).empty])\n",
    ")\n",
    "display(\n",
    "    train['created'].min(),\n",
    "    train['created'].max(),\n",
    "    validation['created'].min(),\n",
    "    validation['created'].max(),\n",
    "    test['created'].min(),\n",
    "    test['created'].max(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd1c7a4",
   "metadata": {},
   "source": [
    "#### e. Make split procedure determenistic. What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eaccaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Каждая реализация my_train_test_split сопровождена детерминацией, однако,\n",
    "    в функциях со стратегией 'Out-of-time' (например, my_date_train_test_split)\n",
    "    детерминация не требуется, поскольку данные разделяются по времени,\n",
    "    а не случайным образом.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b730a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 4. **Implement the next cross-validation methods:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a89d41",
   "metadata": {},
   "source": [
    "#### a. K-Fold, where k is the input parameter, returns a list of train and test indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c86d931",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.a\n",
    "def my_kfold_cv(X, k=5):\n",
    "    \"\"\"K-Fold разбиение: возвращает список (train_idx, test_idx).\"\"\"\n",
    "    if X is None or len(X) == 0:\n",
    "        raise ValueError(\"X не должен быть пустым\")\n",
    "    if k <= 1 or k > len(X):\n",
    "        raise ValueError(\"k должен быть в диапазоне [2, len(X)]\")\n",
    "\n",
    "    result = []\n",
    "    n = len(X)\n",
    "    all_idx = np.arange(n)\n",
    "    folds = np.array_split(all_idx, k)\n",
    "\n",
    "    for test_idx in folds:\n",
    "        train_idx = all_idx[~np.isin(all_idx, test_idx)]\n",
    "        result.append((train_idx, test_idx))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb9d870",
   "metadata": {},
   "source": [
    "#### b. Grouped K-Fold, where k and group_field are input parameters, returns list of train and test indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4573f895",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.b\n",
    "def my_group_kfold_cv(X, group_field, k=5):\n",
    "    \"\"\"Group K-Fold: разбиение по группам без их пересечений.\"\"\"\n",
    "    if X is None or len(X) == 0:\n",
    "        raise ValueError(\"X не должен быть пустым\")\n",
    "    if group_field is None:\n",
    "        raise ValueError(\"'group_field' должен быть задан\")\n",
    "    if group_field not in X.columns:\n",
    "        raise ValueError(f\"Поле '{group_field}' отсутствует в X\")\n",
    "    if k <= 1 or k > len(X):\n",
    "        raise ValueError(\"k должен быть в диапазоне [2, len(X)]\")\n",
    "\n",
    "    result = []\n",
    "    n = len(X)\n",
    "    group_values = np.asarray(X[group_field])\n",
    "\n",
    "    unique_groups, inv_idx, counts = np.unique(\n",
    "        group_values, return_inverse=True, return_counts=True\n",
    "    )\n",
    "    if len(unique_groups) < k:\n",
    "        raise ValueError(\"Уникальных групп меньше, чем k\")\n",
    "\n",
    "    indices_by_group = {}\n",
    "    for i, g in enumerate(unique_groups):\n",
    "        indices_by_group[g] = np.where(inv_idx == i)[0].tolist()\n",
    "\n",
    "    order = np.argsort(counts)[::-1]\n",
    "    unique_groups = unique_groups[order]\n",
    "    counts = counts[order]\n",
    "\n",
    "    fold_sizes = np.zeros(k, dtype=int)\n",
    "    folds = [[] for _ in range(k)]\n",
    "    for g, c in zip(unique_groups, counts):\n",
    "        fold_id = np.argmin(fold_sizes)\n",
    "        folds[fold_id].extend(indices_by_group[g])\n",
    "        fold_sizes[fold_id] += c\n",
    "\n",
    "    for test_idx in folds:\n",
    "        mask = np.ones(n, dtype=bool)\n",
    "        mask[test_idx] = False\n",
    "        train_idx = np.nonzero(mask)[0]\n",
    "        result.append((train_idx, np.array(sorted(test_idx))))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71b2b68",
   "metadata": {},
   "source": [
    "#### c. Stratified K-fold, where k and stratify_field are input parameters, returns list of train and test indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef621474",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "price_category\n",
       "low       17286\n",
       "middle    17269\n",
       "high      14797\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"price_category\"] = pd.cut(\n",
    "    df[\"price\"],\n",
    "    bins=[-np.inf, 2700, 3800, np.inf],\n",
    "    labels=[\"low\", \"middle\", \"high\"]\n",
    ")\n",
    "df[\"price_category\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8543b251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.c\n",
    "def my_stratified_kfold_cv(X, stratify_field, k=5):\n",
    "    \"\"\"Stratified K-Fold: сохраняет пропорции классов в каждом фолде.\"\"\"\n",
    "    if X is None or len(X) == 0:\n",
    "        raise ValueError(\"X не должен быть пустым\")\n",
    "    if stratify_field is None:\n",
    "        raise ValueError(\"'stratify_field' должен быть задан\")\n",
    "    if stratify_field not in X.columns:\n",
    "        raise ValueError(f\"Поле '{stratify_field}' отсутствует в X\")\n",
    "    if k <= 1 or k > len(X):\n",
    "        raise ValueError(\"k должен быть в диапазоне [2, len(X)]\")\n",
    "\n",
    "    result = []\n",
    "    n = len(X)\n",
    "    y = np.asarray(X[stratify_field])\n",
    "\n",
    "    unique_classes, counts = np.unique(y, return_counts=True)\n",
    "    if counts.min() < k:\n",
    "        raise ValueError(\"Минимальный класс содержит меньше объектов, чем k\")\n",
    "\n",
    "    folds = [[] for _ in range(k)]\n",
    "    for cls in unique_classes:\n",
    "        class_idx = np.where(y == cls)[0]\n",
    "        parts = np.array_split(class_idx, k)\n",
    "        for i in range(k):\n",
    "            folds[i].append(parts[i])\n",
    "\n",
    "    all_idx = np.arange(n)\n",
    "    for i in range(k):\n",
    "        test_idx = np.concatenate(folds[i])\n",
    "        train_idx = np.setdiff1d(all_idx, test_idx, assume_unique=False)\n",
    "        result.append((train_idx, test_idx))\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4cd2473",
   "metadata": {},
   "source": [
    "#### d. Time series split, where k and date_field are input parameters, returns list of train and test indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f23031fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 4.d\n",
    "def my_time_series_split(X, date_field=None, k=5):\n",
    "    \"\"\"TimeSeriesSplit: train — прошлое, test — следующий блок.\"\"\"\n",
    "    if X is None or len(X) == 0:\n",
    "        raise ValueError(\"X не должен быть пустым\")\n",
    "    if date_field is None:\n",
    "        raise ValueError(\"'date_field' должен быть задан\")\n",
    "    if date_field not in X.columns:\n",
    "        raise ValueError(f\"Поле '{date_field}' отсутствует в X\")\n",
    "    if k <= 1 or k > len(X):\n",
    "        raise ValueError(\"k должен быть в диапазоне [2, len(X)]\")\n",
    "\n",
    "    result = []\n",
    "    index_array = X.index.to_numpy()\n",
    "    n = len(index_array)\n",
    "\n",
    "    n_folds = k + 1\n",
    "    test_size = n // n_folds\n",
    "    remainder = n % n_folds\n",
    "    train_end = remainder + test_size\n",
    "\n",
    "    for _ in range(k):\n",
    "        test_start = train_end\n",
    "        test_end = test_start + test_size\n",
    "        result.append((index_array[:train_end], index_array[test_start:test_end]))\n",
    "        train_end += test_size\n",
    "\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d7cb6a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 5. **Cross-validation comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046e99f",
   "metadata": {},
   "source": [
    "#### a. Apply all the validation methods implemented above to our dataset. To apply Stratified algorithm you should preprocess target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7acfac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.a\n",
    "n_folds = 5\n",
    "\n",
    "my_train_test_kf = my_kfold_cv(df, k=n_folds)\n",
    "my_train_test_gkf = my_group_kfold_cv(df, \"building_id\", k=n_folds)\n",
    "my_train_test_skf = my_stratified_kfold_cv(df, \"price_category\", k=n_folds)\n",
    "my_train_test_tss = my_time_series_split(df, \"created\", n_folds)\n",
    "\n",
    "my_methods = {\"MyKFold\": my_train_test_kf,\n",
    "              \"MyGroupKFold\": my_train_test_gkf,\n",
    "              \"MyStratifiedKFold\": my_train_test_skf,\n",
    "              \"MyTimeSeriesSplit\": my_train_test_tss}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9f8a7d1",
   "metadata": {},
   "source": [
    "#### b. Apply the appropriate methods from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e7f40abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5.b\n",
    "from sklearn.model_selection import (KFold,\n",
    "                                     GroupKFold,\n",
    "                                     StratifiedKFold,\n",
    "                                     TimeSeriesSplit)\n",
    "\n",
    "train_test_kf = list(KFold(n_folds).split(df))\n",
    "train_test_gkf = list(GroupKFold(n_folds).split(df, groups=df[\"building_id\"]))\n",
    "train_test_skf = list(StratifiedKFold(n_folds).split(df, df[\"price_category\"]))\n",
    "train_test_tss = list(TimeSeriesSplit(n_folds).split(df, \"created\"))\n",
    "\n",
    "base_methods = {\"KFold\": list(train_test_kf),\n",
    "                \"GroupKFold\": list(train_test_gkf),\n",
    "                \"StratifiedKFold\": list(train_test_skf),\n",
    "                \"TimeSeriesSplit\": list(train_test_tss)}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df757757",
   "metadata": {},
   "source": [
    "#### c. Compare the resulting feature distributions for the training part of the dataset between sklearn and your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7f67d96d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Сравнение MyKFold и KFold: Идентичны\n",
      "Сравнение MyKFold и KFold: Идентичны\n",
      "Сравнение MyKFold и KFold: Идентичны\n",
      "Сравнение MyKFold и KFold: Идентичны\n",
      "Сравнение MyKFold и KFold: Идентичны\n",
      "\n",
      "Сравнение MyGroupKFold и GroupKFold: Идентичны\n",
      "Сравнение MyGroupKFold и GroupKFold: Идентичны\n",
      "Сравнение MyGroupKFold и GroupKFold: Идентичны\n",
      "Сравнение MyGroupKFold и GroupKFold: Идентичны\n",
      "Сравнение MyGroupKFold и GroupKFold: Идентичны\n",
      "\n",
      "Сравнение MyStratifiedKFold и StratifiedKFold: Различаются\n",
      "Сравнение MyStratifiedKFold и StratifiedKFold: Различаются\n",
      "Сравнение MyStratifiedKFold и StratifiedKFold: Различаются\n",
      "Сравнение MyStratifiedKFold и StratifiedKFold: Различаются\n",
      "Сравнение MyStratifiedKFold и StratifiedKFold: Различаются\n",
      "\n",
      "Сравнение MyTimeSeriesSplit и TimeSeriesSplit: Идентичны\n",
      "Сравнение MyTimeSeriesSplit и TimeSeriesSplit: Идентичны\n",
      "Сравнение MyTimeSeriesSplit и TimeSeriesSplit: Идентичны\n",
      "Сравнение MyTimeSeriesSplit и TimeSeriesSplit: Идентичны\n",
      "Сравнение MyTimeSeriesSplit и TimeSeriesSplit: Идентичны\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 5.c\n",
    "compare = (lambda x, y: np.array_equal(x, y))\n",
    "for my, base in zip(my_methods.items(), base_methods.items()):\n",
    "    for fold in range(n_folds):\n",
    "        arr1 = base[1][fold][0]\n",
    "        arr2 = my[1][fold][0]\n",
    "        print(f\"Сравнение {my[0]} и {base[0]}:\", (\"Идентичны\"\n",
    "                                                  if compare(arr1, arr2)\n",
    "                                                  else \"Различаются\"))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1e525c3e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 9785,  9786,  9787, ..., 49349, 49350, 49351], shape=(39480,)),\n",
       "  array([   5,    6,    9, ..., 9819, 9821, 9823], shape=(9872,))),\n",
       " (array([    0,     1,     2, ..., 49349, 49350, 49351], shape=(39481,)),\n",
       "  array([ 9785,  9786,  9787, ..., 19650, 19651, 19652], shape=(9871,))),\n",
       " (array([    0,     1,     2, ..., 49349, 49350, 49351], shape=(39482,)),\n",
       "  array([19535, 19537, 19541, ..., 29693, 29696, 29698], shape=(9870,))),\n",
       " (array([    0,     1,     2, ..., 49349, 49350, 49351], shape=(39482,)),\n",
       "  array([29197, 29198, 29199, ..., 39555, 39557, 39560], shape=(9870,))),\n",
       " (array([    0,     1,     2, ..., 39721, 39723, 39727], shape=(39483,)),\n",
       "  array([39090, 39111, 39112, ..., 49344, 49345, 49347], shape=(9869,)))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[(array([ 9785,  9786,  9787, ..., 49349, 49350, 49351], shape=(39481,)),\n",
       "  array([    0,     1,     2, ..., 10024, 10030, 10035], shape=(9871,))),\n",
       " (array([    0,     1,     2, ..., 49349, 49350, 49351], shape=(39481,)),\n",
       "  array([ 9785,  9786,  9787, ..., 19978, 19981, 19983], shape=(9871,))),\n",
       " (array([    0,     1,     2, ..., 49349, 49350, 49351], shape=(39482,)),\n",
       "  array([19535, 19537, 19541, ..., 29872, 29874, 29876], shape=(9870,))),\n",
       " (array([    0,     1,     2, ..., 49349, 49350, 49351], shape=(39482,)),\n",
       "  array([29197, 29198, 29199, ..., 39721, 39723, 39727], shape=(9870,))),\n",
       " (array([    0,     1,     2, ..., 39721, 39723, 39727], shape=(39482,)),\n",
       "  array([39090, 39111, 39112, ..., 49349, 49350, 49351], shape=(9870,)))]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 5.c.a\n",
    "display(\n",
    "    my_train_test_skf,\n",
    "    train_test_skf\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93c94ddb",
   "metadata": {},
   "source": [
    "#### d. Compare all validation schemes. Choose the best one. Explain your choice."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe9aab74",
   "metadata": {},
   "source": [
    "##### __5.d__\n",
    "> Изучив \"под капотом\" каждый метод кросс валидации, я пришел к выводу, что лучшим методом является `StratifiedKFold` для стратегии `out-of-fold`, т.к. метод `StratifiedKFold` сохраняет баланс в целевых признаках, что уменьшает смещение предсказаний в сторону одной метки. Например, в нашем случае `df[\"price\"]` имеет достаточно высокие __*стандартное отклонение $\\left(\\sigma ^ 2\\right)$ и дисперсию $\\left(\\sigma = \\sqrt{\\sigma ^ 2}\\right)$*__, что говорит о высоком разбросе целевого признака `\"price\"` в датафрэйме. Также, визуализация распределения `\"price\"` из предыдущих задач показала, что `\"price\"` имеет сильное левостороннее смещение (длинный правый хвост, распределение не является нормальным), а это значит, что модель чаще будет предсказывать значения области \"высокой плотности\". Мы можем обработать это смещение, либо преобразовать его из чисел в __*диапазоны/категории*__. `StratifiedKFold` требует предобработки числовых меток и это следует учитывать."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1686f2ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 6. **Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f330f09",
   "metadata": {},
   "source": [
    "#### a. Fit a Lasso regression model with normalized features. Use your method for splitting samples into 3 parts by field created with 60/20/20 ratio — train/validation/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ec4063f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: #000;\n",
       "  --sklearn-color-text-muted: #666;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: flex;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "  align-items: start;\n",
       "  justify-content: space-between;\n",
       "  gap: 0.5em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label .caption {\n",
       "  font-size: 0.6rem;\n",
       "  font-weight: lighter;\n",
       "  color: var(--sklearn-color-text-muted);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  display: none;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  overflow: visible;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 0.5em;\n",
       "  text-align: center;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".estimator-table summary {\n",
       "    padding: .5rem;\n",
       "    font-family: monospace;\n",
       "    cursor: pointer;\n",
       "}\n",
       "\n",
       ".estimator-table details[open] {\n",
       "    padding-left: 0.1rem;\n",
       "    padding-right: 0.1rem;\n",
       "    padding-bottom: 0.3rem;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table {\n",
       "    margin-left: auto !important;\n",
       "    margin-right: auto !important;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(odd) {\n",
       "    background-color: #fff;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:nth-child(even) {\n",
       "    background-color: #f6f6f6;\n",
       "}\n",
       "\n",
       ".estimator-table .parameters-table tr:hover {\n",
       "    background-color: #e0e0e0;\n",
       "}\n",
       "\n",
       ".estimator-table table td {\n",
       "    border: 1px solid rgba(106, 105, 104, 0.232);\n",
       "}\n",
       "\n",
       ".user-set td {\n",
       "    color:rgb(255, 94, 0);\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td.value pre {\n",
       "    color:rgb(255, 94, 0) !important;\n",
       "    background-color: transparent !important;\n",
       "}\n",
       "\n",
       ".default td {\n",
       "    color: black;\n",
       "    text-align: left;\n",
       "}\n",
       "\n",
       ".user-set td i,\n",
       ".default td i {\n",
       "    color: black;\n",
       "}\n",
       "\n",
       ".copy-paste-icon {\n",
       "    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);\n",
       "    background-repeat: no-repeat;\n",
       "    background-size: 14px 14px;\n",
       "    background-position: 0;\n",
       "    display: inline-block;\n",
       "    width: 14px;\n",
       "    height: 14px;\n",
       "    cursor: pointer;\n",
       "}\n",
       "</style><body><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Lasso(alpha=32.3809, max_iter=10000, random_state=21)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow\"><div><div>Lasso</div></div><div><a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.7/modules/generated/sklearn.linear_model.Lasso.html\">?<span>Documentation for Lasso</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></div></label><div class=\"sk-toggleable__content fitted\" data-param-prefix=\"\">\n",
       "        <div class=\"estimator-table\">\n",
       "            <details>\n",
       "                <summary>Parameters</summary>\n",
       "                <table class=\"parameters-table\">\n",
       "                  <tbody>\n",
       "                    \n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('alpha',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">alpha&nbsp;</td>\n",
       "            <td class=\"value\">32.3809</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('fit_intercept',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">fit_intercept&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('precompute',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">precompute&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('copy_X',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">copy_X&nbsp;</td>\n",
       "            <td class=\"value\">True</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('max_iter',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">max_iter&nbsp;</td>\n",
       "            <td class=\"value\">10000</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('tol',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">tol&nbsp;</td>\n",
       "            <td class=\"value\">0.0001</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('warm_start',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">warm_start&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('positive',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">positive&nbsp;</td>\n",
       "            <td class=\"value\">False</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"user-set\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('random_state',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">random_state&nbsp;</td>\n",
       "            <td class=\"value\">21</td>\n",
       "        </tr>\n",
       "    \n",
       "\n",
       "        <tr class=\"default\">\n",
       "            <td><i class=\"copy-paste-icon\"\n",
       "                 onclick=\"copyToClipboard('selection',\n",
       "                          this.parentElement.nextElementSibling)\"\n",
       "            ></i></td>\n",
       "            <td class=\"param\">selection&nbsp;</td>\n",
       "            <td class=\"value\">&#x27;cyclic&#x27;</td>\n",
       "        </tr>\n",
       "    \n",
       "                  </tbody>\n",
       "                </table>\n",
       "            </details>\n",
       "        </div>\n",
       "    </div></div></div></div></div><script>function copyToClipboard(text, element) {\n",
       "    // Get the parameter prefix from the closest toggleable content\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;\n",
       "\n",
       "    const originalStyle = element.style;\n",
       "    const computedStyle = window.getComputedStyle(element);\n",
       "    const originalWidth = computedStyle.width;\n",
       "    const originalHTML = element.innerHTML.replace('Copied!', '');\n",
       "\n",
       "    navigator.clipboard.writeText(fullParamName)\n",
       "        .then(() => {\n",
       "            element.style.width = originalWidth;\n",
       "            element.style.color = 'green';\n",
       "            element.innerHTML = \"Copied!\";\n",
       "\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        })\n",
       "        .catch(err => {\n",
       "            console.error('Failed to copy:', err);\n",
       "            element.style.color = 'red';\n",
       "            element.innerHTML = \"Failed!\";\n",
       "            setTimeout(() => {\n",
       "                element.innerHTML = originalHTML;\n",
       "                element.style = originalStyle;\n",
       "            }, 2000);\n",
       "        });\n",
       "    return false;\n",
       "}\n",
       "\n",
       "document.querySelectorAll('.fa-regular.fa-copy').forEach(function(element) {\n",
       "    const toggleableContent = element.closest('.sk-toggleable__content');\n",
       "    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';\n",
       "    const paramName = element.parentElement.nextElementSibling.textContent.trim();\n",
       "    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;\n",
       "\n",
       "    element.setAttribute('title', fullParamName);\n",
       "});\n",
       "</script></body>"
      ],
      "text/plain": [
       "Lasso(alpha=32.3809, max_iter=10000, random_state=21)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.a\n",
    "from sklearn.linear_model import Lasso\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "\n",
    "df_prepare = df[rooms + features + target].copy()\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "df_prepare[rooms + features] = scaler.fit_transform(df_prepare[rooms + features])\n",
    "\n",
    "train, validation, test = my_train_validation_test_split(\n",
    "    df_prepare.drop(columns=\"price\"),\n",
    "    df_prepare[\"price\"],\n",
    "    validation_size=0.2,\n",
    "    test_size=0.2,\n",
    "    random_state=21,\n",
    ")\n",
    "lasso = Lasso(alpha=32.3809, random_state=21, max_iter=10_000)\n",
    "lasso.fit(train.drop(columns=\"price\"), train[\"price\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca071d2",
   "metadata": {},
   "source": [
    "#### b. Sort features by weight coefficients from model, fit model to top 10 features and compare quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3055d092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Importance</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>bathrooms</td>\n",
       "      <td>7029.967698</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bedrooms</td>\n",
       "      <td>5719.554972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Doorman</td>\n",
       "      <td>1285.859918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LaundryinUnit</td>\n",
       "      <td>488.325535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Elevator</td>\n",
       "      <td>432.521756</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LaundryinBuilding</td>\n",
       "      <td>423.666310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>NoFee</td>\n",
       "      <td>279.017578</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>HardwoodFloors</td>\n",
       "      <td>247.807192</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>DogsAllowed</td>\n",
       "      <td>240.873815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LaundryInBuilding</td>\n",
       "      <td>137.935836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>DiningRoom</td>\n",
       "      <td>105.294316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>FitnessCenter</td>\n",
       "      <td>49.376459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>CatsAllowed</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Dishwasher</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>RoofDeck</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>Pre-War</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>HighSpeedInternet</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>OutdoorSpace</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Balcony</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SwimmingPool</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>NewConstruction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>Terrace</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Name   Importance\n",
       "0           bathrooms  7029.967698\n",
       "1            bedrooms  5719.554972\n",
       "2             Doorman  1285.859918\n",
       "3       LaundryinUnit   488.325535\n",
       "4            Elevator   432.521756\n",
       "5   LaundryinBuilding   423.666310\n",
       "6               NoFee   279.017578\n",
       "7      HardwoodFloors   247.807192\n",
       "8         DogsAllowed   240.873815\n",
       "9   LaundryInBuilding   137.935836\n",
       "10         DiningRoom   105.294316\n",
       "11      FitnessCenter    49.376459\n",
       "12        CatsAllowed     0.000000\n",
       "13         Dishwasher     0.000000\n",
       "14           RoofDeck     0.000000\n",
       "15            Pre-War     0.000000\n",
       "16  HighSpeedInternet     0.000000\n",
       "17       OutdoorSpace     0.000000\n",
       "18            Balcony     0.000000\n",
       "19       SwimmingPool     0.000000\n",
       "20    NewConstruction     0.000000\n",
       "21            Terrace     0.000000"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 6.b\n",
    "feature_names = lasso.feature_names_in_\n",
    "feature_weights = np.abs(lasso.coef_).round(6)\n",
    "weights = pd.DataFrame({\n",
    "    \"Name\": feature_names,\n",
    "    \"Importance\": feature_weights}\n",
    ")\n",
    "most_important = weights.sort_values(by=\"Importance\", ascending=False)\n",
    "most_important.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1262a5d",
   "metadata": {},
   "source": [
    "#### c. Implement method for simple feature selection by nan-ratio in feature and correlation. Apply this method to feature set and take top 10 features, refit model and measure quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a66378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29f95f49",
   "metadata": {},
   "source": [
    "#### d. Implement permutation importance method and take top 10 features, refit model and measure quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5abf40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87f72988",
   "metadata": {},
   "source": [
    "#### e. Import Shap and also refit model on top 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d32ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7de62330",
   "metadata": {},
   "source": [
    "#### f. Compare the quality of these methods for different aspects — speed, metrics and stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887a524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c86d86e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 7. **Hyperparameter optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524151e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### a. Implement grid search and random search methods for alpha and l1_ratio for sklearn's ElasticNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13434909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e30f5382",
   "metadata": {},
   "source": [
    "#### b. Find the best combination of model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89db2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75b375b0",
   "metadata": {},
   "source": [
    "#### c. Fit the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ebcfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ceeecd2",
   "metadata": {},
   "source": [
    "#### d. Import optuna and configure the same experiment with ElasticNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb15c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7bc879c",
   "metadata": {},
   "source": [
    "#### e. Estimate metrics and compare approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430eb31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3eb2aec",
   "metadata": {},
   "source": [
    "#### f. Run optuna on one of the cross-validation schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b7b584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
