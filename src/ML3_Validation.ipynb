{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "228f2262",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "## **Chapter V. Task**\n",
    "\n",
    "We will continue our training with a problem from Kaggle.com. \n",
    "In this chapter, we will implement all the validation schemes, some hyperparameter tuning methods, and feature selection methods described above. Measure quality metrics on training and test samples. Will detect overfitted models and regularize them. And dive deeper with native model estimation and comparison."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "013f5fef",
   "metadata": {},
   "source": [
    "### 1. **Answer the questions from the introduction**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "109c16cf",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### a. What is leave-one-out? Provide limitations and strengths.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5dd72f3d",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "Leave-One-Out кросс валидация - это частный случай k-fold Cross Validation, где k = n. Данные размерности 10 делятся на обучающую и тестовую выборки по принципу 9 обучающей и 1 тестовая на каждой итерации для всех данных. При этом,каждый набор данных __ровно один раз__ становится тестовым (см. пример кода.). Другими словами, для **_n_** образцов мы имеем **_n-1_** тренировочных данных и **1** тестовый набор.\n",
    "Достоинства:\n",
    " * максимальное использование данных для обучения\n",
    " * не зависит от случайного разбиения\n",
    " * эффективен только на маленьких наборах данных\n",
    "\n",
    "Недостатки:\n",
    " * высокая стоимость вычислительных операций для больших выборок данных - O(n)\n",
    " * высокая дисперсия оценки\n",
    " * может недооценивать ошибку на новых данных\n",
    "\n",
    "```Python\n",
    ">>> from sklearn.model_selection import LeaveOneOut\n",
    "\n",
    ">>> X = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10]\n",
    ">>> loo = LeaveOneOut()\n",
    ">>> for train, test in loo.split(X):\n",
    "...     print(\"%s %s\" % (train, test))\n",
    "\n",
    "[1 2 3 4 5 6 7 8 9] [0]\n",
    "[0 2 3 4 5 6 7 8 9] [1]\n",
    "[0 1 3 4 5 6 7 8 9] [2]\n",
    "[0 1 2 4 5 6 7 8 9] [3]\n",
    "[0 1 2 3 5 6 7 8 9] [4]\n",
    "[0 1 2 3 4 6 7 8 9] [5]\n",
    "[0 1 2 3 4 5 7 8 9] [6]\n",
    "[0 1 2 3 4 5 6 8 9] [7]\n",
    "[0 1 2 3 4 5 6 7 9] [8]\n",
    "[0 1 2 3 4 5 6 7 8] [9]\n",
    "```\n",
    "\n",
    "Источник: https://scikit-learn.org/stable/modules/cross_validation.html#leave-one-out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9eb16e96",
   "metadata": {},
   "source": [
    "#### b. How do Grid Search, Randomized Grid Search, and Bayesian optimization work?  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dc7c9e6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "A = {1, 2, 3, 4, 5}\n",
    "B = {6, 7, 8, 9}\n",
    "C = {10, 11, 12}\n",
    "\n",
    "def cartesian_product(*sets):\n",
    "    \"\"\"\n",
    "    Декартово произведение множеств\n",
    "    \"\"\"\n",
    "    result = [[]]\n",
    "    for pool in sets:\n",
    "        result = [x + [y] for x in result for y in pool]\n",
    "    return [tuple(item) for item in result]\n",
    "\n",
    "decart = cartesian_product(A, B, C)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c342136f",
   "metadata": {},
   "source": [
    "> Этапы работы поиска наилучших гиперпараметров через Grid Search:\n",
    " 1. **Определение пространства внешних гиперпараметров**. На первом этапе необходимо обозначить какие гиперпараметры мы ищем. Параметр должен содержать множество значений, по которым мы будем проводить поиск. Параметров может быть несколько. Несколько параметров собираются в единый словарь, где ключи — имена гиперпараметров, а значения — списки возможных значений для каждого параметра.\n",
    " 2. **Создание сетки гиперпараметров**. Создается декартово произведение всех списков значений, получая полный набор всех возможных комбинаций гиперпараметров.\n",
    " 3. **Проход по списку гиперпараметров**. Алгоритм GridSearch последовательно проходит по каждой комбинации гиперпараметров, обучается и оценивается с помощью k-fold CV, вычисляется средняя оценка гиперпараметров по всем фолдам для заданной метрики.\n",
    " 4. **Сохранение и возвращение результата**. По окончании подбора параметров выбирается комбинация с наилучшей средней оценкой. GridSearch возвращает: лучшие гиперпараметры `best_params_`; лучшие оценки `best_score_`; полную информацию по всем комбинациям `cv_results_`.\n",
    "\n",
    "> Randomized Grid Search:\n",
    " * Принцип работы Randomized Grid Search схож с работой Grid Search, но не создает полную сетку всех комбинаций гиперпараметров. Вместо этого поиск происходит случайным образом. Еще одно отличие - это наличие итераций. На каждой итерации `n_iter` случайным образом генерируется комбинация гиперпараметров, происходит обучение модели и оценка её качества с помощью k-fold CV на всех фолдах. Случайный выбор позволяет ускорить процесс подбора гиперпараметров. В таком случае, гиперпараметры следует задавать не только дискретным образом, но и в диапазоне и\\или распределении, например: `stats.uniform(0.1, 10)`, здесь будет создано распределение случайных чисел от 0.1 до 10 + 0.1. Случайное число из данного распределения будет получено внутри GridSearch.\n",
    "\n",
    "> Bayesian optimization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13fa1c8d",
   "metadata": {},
   "source": [
    "#### c. Explain classification of feature selection methods. Explain how Pearson and Chi2 work. Explain how Lasso works. Explain what permutation significance is. Become familiar with SHAP.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b373400e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "095d59ab",
   "metadata": {},
   "source": [
    "### **2. Introduction — do all the preprocessing from the previous lesson**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "99c3476e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.Imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daecaf5",
   "metadata": {},
   "source": [
    "#### a. Read all the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d2b5df30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.a\n",
    "df = pd.read_json(\n",
    "    \"../datasets/train.json\",\n",
    "    convert_dates=[\"created\"]\n",
    ").reset_index(drop=True)\n",
    "    # pd.read_json(\"../datasets/test.json\") - здесь нет признака 'interest_level'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1dfd6b",
   "metadata": {},
   "source": [
    "#### b. Create features: 'Elevator', 'HardwoodFloors', 'CatsAllowed', 'DogsAllowed', 'Doorman', 'Dishwasher', 'NoFee', 'LaundryinBuilding', 'FitnessCenter', 'Pre-War', 'LaundryinUnit', 'RoofDeck', 'OutdoorSpace', 'DiningRoom', 'HighSpeedInternet', 'Balcony', 'SwimmingPool', 'LaundryInBuilding', 'NewConstruction', 'Terrace'.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ebdd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2.b\n",
    "pattern = re.compile(r\"[\\[\\]\\'\\\"\\s]\")\n",
    "remove_sym = (lambda x: list([re.sub(pattern, '', elem) for elem in x]))\n",
    "df[\"features\"] = df[\"features\"].apply(remove_sym)\n",
    "\n",
    "target = [\"price\"]\n",
    "rooms = [\"bedrooms\", \"bathrooms\"]\n",
    "features = ['Elevator', 'HardwoodFloors', 'CatsAllowed', 'DogsAllowed',\n",
    "            'Doorman', 'Dishwasher', 'NoFee', 'LaundryinBuilding',\n",
    "            'FitnessCenter', 'Pre-War', 'LaundryinUnit', 'RoofDeck',\n",
    "            'OutdoorSpace', 'DiningRoom', 'HighSpeedInternet', 'Balcony',\n",
    "            'SwimmingPool', 'LaundryInBuilding', 'NewConstruction', 'Terrace',]\n",
    "for feature in features:\n",
    "    df[feature] = (\n",
    "        df[\"features\"]\n",
    "        .apply(lambda x: 1 if feature in x else 0)\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25651014",
   "metadata": {},
   "source": [
    "### 3. **Implement the next methods:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac7006ca",
   "metadata": {},
   "source": [
    "#### a. Split data into 2 parts randomly with parameter test_size (ratio from 0 to 1), return training and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b66524c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of the samples is identical: True \n",
      "Sample sizes: train(39481, 35), test(9871, 35) \n",
      "There are no intersections: True\n"
     ]
    }
   ],
   "source": [
    "# 3.a\n",
    "def my_train_test_split(X, y, test_size=0.25, random_state=None, shuffle=True):\n",
    "    random = np.random.RandomState(random_state)\n",
    "    if np.array_equal(X.index.to_numpy(), y.index.to_numpy()) is False:\n",
    "        raise ValueError(\"Indices of 'X' and 'y' must be equal\")\n",
    "\n",
    "    n = len(X)\n",
    "    if isinstance(test_size, int):\n",
    "        if test_size <= 0 or test_size >= n:\n",
    "            raise ValueError(\"'test_size' must be between 1 and len(X)-1\")\n",
    "    elif isinstance(test_size, float):\n",
    "        if test_size <= 0.0 or test_size >= 1.0:\n",
    "            raise ValueError(\"'test_size' must be between 0.0 and 1.0\")\n",
    "        test_size = ceil(n * test_size)\n",
    "    else:\n",
    "        raise ValueError(\"'test_size' must be float or int\")\n",
    "\n",
    "    idx = X.index.to_numpy()\n",
    "    if shuffle:\n",
    "        random = np.random.RandomState(random_state)\n",
    "        idx = random.permutation(idx)\n",
    "\n",
    "    train_idxs = idx[test_size:]\n",
    "    test_idxs = idx[:test_size]\n",
    "\n",
    "    return (pd.concat([X.loc[train_idxs], y.loc[train_idxs]], axis=1),\n",
    "            pd.concat([X.loc[test_idxs], y.loc[test_idxs]], axis=1))\n",
    "\n",
    "\n",
    "train, test = my_train_test_split(\n",
    "    df.drop(columns=target),\n",
    "    df[target],\n",
    "    test_size=0.2\n",
    ")\n",
    "train_idx, test_idx = train.index, test.index\n",
    "print(\n",
    "    \"The sum of the samples is identical: \" +\n",
    "    f\"{train.shape[0] + test.shape[0] == len(df)}\",\n",
    "    \"\\nSample sizes: \" +\n",
    "    f\"train{train.shape}, test{test.shape}\",\n",
    "    \"\\nThere are no intersections:\", all([train_idx.intersection(test_idx).empty,\n",
    "                                          test_idx.intersection(train_idx).empty])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba02c8cb",
   "metadata": {},
   "source": [
    "#### b. Randomly split data into 3 parts with parameters validation_size and test_size, return train, validation and test samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1e14674e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of the samples is identical: True \n",
      "Sample sizes: train(29610, 35), validation(9871, 35), test(9871, 35) \n",
      "There are no intersections: True\n"
     ]
    }
   ],
   "source": [
    "# 3.b\n",
    "def my_train_validation_test_split(X,\n",
    "                                   y,\n",
    "                                   validation_size=0.25,\n",
    "                                   test_size=0.25,\n",
    "                                   random_state=None,\n",
    "                                   shuffle=True):\n",
    "    random = np.random.RandomState(random_state)\n",
    "    if np.array_equal(X.index.to_numpy(), y.index.to_numpy()) is False:\n",
    "        raise ValueError(\"Indices of 'X' and 'y' must be equal\")\n",
    "\n",
    "    n = len(X)\n",
    "    if isinstance(test_size, int) and isinstance(validation_size, int):\n",
    "        if test_size <= 0 or test_size >= n:\n",
    "            raise ValueError(\"'test_size' must be between 1 and len(X)-1\")\n",
    "        if validation_size <= 0 or validation_size >= n:\n",
    "            raise ValueError(\"'validation_size' must be between 1 and len(X)-1\")\n",
    "    elif isinstance(test_size, float) and isinstance(validation_size, float):\n",
    "        if test_size <= 0.0 or test_size >= 1.0:\n",
    "            raise ValueError(\"'test_size' must be between 0.0 and 1.0\")\n",
    "        if validation_size <= 0.0 or validation_size >= 1.0:\n",
    "            raise ValueError(\"'validation_size' must be between 0.0 and 1.0\")\n",
    "        if test_size + validation_size >= 1:\n",
    "            raise ValueError(\"test_size + validation_size must be < 1\")\n",
    "        test_size = ceil(n * test_size)\n",
    "        validation_size = ceil(n * validation_size)\n",
    "    else:\n",
    "        raise ValueError(\"'test_size'/'validation_size' must be float or int\")\n",
    "    if test_size + validation_size >= n:\n",
    "        raise ValueError(\"test_size + validation_size must be < len(X)\")\n",
    "\n",
    "    idx = X.index.to_numpy()\n",
    "    if shuffle:\n",
    "        random = np.random.RandomState(random_state)\n",
    "        idx = random.permutation(idx)\n",
    "    train_idxs = idx[test_size + validation_size:]\n",
    "    test_idxs = idx[:test_size]\n",
    "    validation_idxs = idx[test_size:test_size + validation_size]\n",
    "\n",
    "    return (pd.concat([X.loc[train_idxs], y.loc[train_idxs]], axis=1),\n",
    "            pd.concat([X.loc[validation_idxs], y.loc[validation_idxs]], axis=1),\n",
    "            pd.concat([X.loc[test_idxs], y.loc[test_idxs]], axis=1))\n",
    "\n",
    "\n",
    "train, validation, test = my_train_validation_test_split(\n",
    "    df.drop(columns=target),\n",
    "    df[target],\n",
    "    validation_size=0.2,\n",
    "    test_size=0.2,\n",
    ")\n",
    "\n",
    "train_idx, validation_idx, test_idx = train.index, validation.index, test.index\n",
    "print(\n",
    "    \"The sum of the samples is identical: \" +\n",
    "    f\"{train.shape[0]+validation.shape[0]+test.shape[0] == len(df)}\",\n",
    "    \"\\nSample sizes: \"\n",
    "    f\"train{train.shape}, validation{validation.shape}, test{test.shape}\",\n",
    "    \"\\nThere are no intersections:\", all([train_idx.intersection(validation_idx).empty,\n",
    "                                          train_idx.intersection(test_idx).empty,\n",
    "                                          validation_idx.intersection(test_idx).empty,\n",
    "                                          test_idx.intersection(train_idx).empty])\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9411783f",
   "metadata": {},
   "source": [
    "#### c. Split data into 2 parts with parameter date_split, return train and test samples split by date_split param."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11634a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of the samples is identical: True \n",
      "Sample sizes: train(41544, 35), test(7808, 35) \n",
      "There are no intersections: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-04-01 22:12:41')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-06-15 23:53:14')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-06-16 00:45:59')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-06-29 21:41:47')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.c\n",
    "def my_date_train_test_split(X, y, date_split=None, random_state=None, shuffle=True):\n",
    "    if np.array_equal(X.index.to_numpy(), y.index.to_numpy()) is False:\n",
    "        raise ValueError(\"Indices of 'X' and 'y' must be equal\")\n",
    "    if date_split is None:\n",
    "        raise ValueError(\"'date_split' must be provided\")\n",
    "\n",
    "    dt_cols = X.select_dtypes(include=[\"datetime\"]).columns\n",
    "    if dt_cols.empty:\n",
    "        raise ValueError(\"X does not contain a timestamp column\")\n",
    "\n",
    "    date_split = pd.to_datetime(date_split)\n",
    "    if not (date_split.date() == X[dt_cols[0]].dt.date).any():\n",
    "        raise ValueError(\n",
    "            f\"'{date_split}' is not contained in the column '{dt_cols[0]}'\"\n",
    "        )\n",
    "    X = X.sort_values(by=dt_cols[0])\n",
    "    y = y.loc[X.index]\n",
    "    train_idx = X[X[dt_cols[0]] < date_split].index.to_numpy()\n",
    "    test_idx = X[X[dt_cols[0]] >= date_split].index.to_numpy()\n",
    "\n",
    "    if shuffle:\n",
    "        random = np.random.RandomState(random_state)\n",
    "        train_idx = random.permutation(train_idx)\n",
    "        test_idx = random.permutation(test_idx)\n",
    "\n",
    "    return (pd.concat([X.loc[train_idx], y.loc[train_idx]], axis=1),\n",
    "            pd.concat([X.loc[test_idx], y.loc[test_idx]], axis=1))\n",
    "\n",
    "\n",
    "train, test = my_date_train_test_split(\n",
    "    df.drop(columns=target),\n",
    "    df[target],\n",
    "    date_split=\"2016-06-16\",\n",
    ")\n",
    "train_idx, test_idx = train.index, test.index\n",
    "print(\n",
    "    \"The sum of the samples is identical: \" +\n",
    "    f\"{train.shape[0] + test.shape[0] == len(df)}\",\n",
    "    \"\\nSample sizes: \" +\n",
    "    f\"train{train.shape}, test{test.shape}\",\n",
    "    \"\\nThere are no intersections:\", all([train_idx.intersection(test_idx).empty,\n",
    "                                          test_idx.intersection(train_idx).empty])\n",
    ")\n",
    "display(\n",
    "    train['created'].min(),\n",
    "    train['created'].max(),\n",
    "    test['created'].min(),\n",
    "    test['created'].max(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71721642",
   "metadata": {},
   "source": [
    "#### d. Split data into 3 parts with parameters validation_date and test_date, return train, validation and test samples split by input params."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23a619f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sum of the samples is identical: True \n",
      "Sample sizes: train(16411, 35), validation(15797, 35), test(17144, 35) \n",
      "There are no intersections: True\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-04-01 22:12:41')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-04-30 19:21:03')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-05-01 22:36:52')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-05-31 23:10:48')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-06-01 01:10:37')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "Timestamp('2016-06-29 21:41:47')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3.d\n",
    "def my_date_train_validation_test_split(X,\n",
    "                                        y,\n",
    "                                        validation_date=None,\n",
    "                                        test_date=None,\n",
    "                                        random_state=None,\n",
    "                                        shuffle=True):\n",
    "    if np.array_equal(X.index.to_numpy(), y.index.to_numpy()) is False:\n",
    "        raise ValueError(\"Indices of 'X' and 'y' must be equal\")\n",
    "    if test_date is None:\n",
    "        raise ValueError(\"'test_date' must be provided\")\n",
    "    if validation_date is None:\n",
    "        raise ValueError(\"'validation_date' must be provided\")\n",
    "\n",
    "    dt_cols = X.select_dtypes(include=[\"datetime\"]).columns\n",
    "    if dt_cols.empty:\n",
    "        raise ValueError(\"X does not contain a timestamp column\")\n",
    "\n",
    "    test_date = pd.to_datetime(test_date)\n",
    "    if not (test_date.date() == X[dt_cols[0]].dt.date).any():\n",
    "        raise ValueError(\n",
    "            f\"'{test_date}' is not contained in the column '{dt_cols[0]}'\"\n",
    "        )\n",
    "\n",
    "    validation_date = pd.to_datetime(validation_date)\n",
    "    if not (validation_date.date() == X[dt_cols[0]].dt.date).any():\n",
    "        raise ValueError(\n",
    "            f\"'{validation_date}' is not contained in the column '{dt_cols[0]}'\"\n",
    "        )\n",
    "    if validation_date == test_date:\n",
    "        raise ValueError(\n",
    "            \"'validation_date' and 'test_date' must be different\"\n",
    "        )\n",
    "    if validation_date > test_date:\n",
    "        raise ValueError(\n",
    "            \"'validation_date' must be less than 'test_date'\"\n",
    "        )\n",
    "    train_idx = X[X[dt_cols[0]] < validation_date].index.to_numpy()\n",
    "    valid_idx = X[(X[dt_cols[0]] >= validation_date) &\n",
    "                  ((X[dt_cols[0]] < test_date))].index.to_numpy()\n",
    "    test_idx = X[X[dt_cols[0]] >= test_date].index.to_numpy()\n",
    "    if shuffle:\n",
    "        random = np.random.RandomState(random_state)\n",
    "        train_idx = random.permutation(train_idx)\n",
    "        valid_idx = random.permutation(valid_idx)\n",
    "        test_idx = random.permutation(test_idx)\n",
    "\n",
    "\n",
    "    return (pd.concat([X.loc[train_idx], y.loc[train_idx]], axis=1),\n",
    "            pd.concat([X.loc[valid_idx], y.loc[valid_idx]], axis=1),\n",
    "            pd.concat([X.loc[test_idx], y.loc[test_idx]], axis=1))\n",
    "\n",
    "\n",
    "train, validation, test = my_date_train_validation_test_split(\n",
    "    df.drop(columns=target),\n",
    "    df[target],\n",
    "    validation_date=\"2016-05-01\",\n",
    "    test_date=\"2016-06-01\",\n",
    "    # random_state=21,\n",
    ")\n",
    "train_idx, test_idx = train.index, test.index\n",
    "print(\n",
    "    \"The sum of the samples is identical: \" +\n",
    "    f\"{train.shape[0] + validation.shape[0] + test.shape[0] == len(df)}\",\n",
    "    \"\\nSample sizes: \" +\n",
    "    f\"train{train.shape}, validation{validation.shape}, test{test.shape}\",\n",
    "    \"\\nThere are no intersections:\", all([train_idx.intersection(test_idx).empty,\n",
    "                                          test_idx.intersection(train_idx).empty])\n",
    ")\n",
    "display(\n",
    "    train['created'].min(),\n",
    "    train['created'].max(),\n",
    "    validation['created'].min(),\n",
    "    validation['created'].max(),\n",
    "    test['created'].min(),\n",
    "    test['created'].max(),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd1c7a4",
   "metadata": {},
   "source": [
    "#### e. Make split procedure determenistic. What does it mean?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eaccaf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    Каждая реализация my_train_test_split сопровождена детерминацией, однако,\n",
    "    в функциях со стратегией 'Out-of-time' (например, my_date_train_test_split)\n",
    "    детерминация не требуется, поскольку данные разделяются по времени,\n",
    "    а не случайным образом.\n",
    "\"\"\";"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "426b730a",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 4. **Implement the next cross-validation methods:**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5a89d41",
   "metadata": {},
   "source": [
    "#### a. K-Fold, where k is the input parameter, returns a list of train and test indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c86d931",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([ 9871,  9872,  9873, ..., 49349, 49350, 49351], shape=(39481,)),\n",
       "  array([   0,    1,    2, ..., 9868, 9869, 9870], shape=(9871,))),\n",
       " (array([    0,     1,     2, ..., 49349, 49350, 49351], shape=(39481,)),\n",
       "  array([ 9871,  9872,  9873, ..., 19739, 19740, 19741], shape=(9871,))),\n",
       " (array([    0,     1,     2, ..., 49349, 49350, 49351], shape=(39482,)),\n",
       "  array([19742, 19743, 19744, ..., 29609, 29610, 29611], shape=(9870,))),\n",
       " (array([    0,     1,     2, ..., 49349, 49350, 49351], shape=(39482,)),\n",
       "  array([29612, 29613, 29614, ..., 39479, 39480, 39481], shape=(9870,))),\n",
       " (array([    0,     1,     2, ..., 39479, 39480, 39481], shape=(39482,)),\n",
       "  array([39482, 39483, 39484, ..., 49349, 49350, 49351], shape=(9870,)))]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4.a\n",
    "def my_kfold_cv(X, n_splits=5, shuffle=True, random_state=None):\n",
    "    result_lst = []\n",
    "    tot_idxs = np.arange(len(X))\n",
    "    if shuffle:\n",
    "        random = np.random.RandomState(random_state)\n",
    "        random.shuffle(tot_idxs)\n",
    "\n",
    "    folds = np.array_split(tot_idxs, n_splits)\n",
    "    for test_idxs in folds:\n",
    "        train_idxs = tot_idxs[~np.isin(tot_idxs, test_idxs)]\n",
    "        result_lst.append((train_idxs, test_idxs))\n",
    "\n",
    "        # Проверка пересечений\n",
    "        assert (X.iloc[train_idxs].index\n",
    "                .intersection(X.iloc[test_idxs].index)).empty == True # True\n",
    "        assert (X.iloc[test_idxs].index\n",
    "                .intersection(X.iloc[train_idxs].index)).empty == True # True\n",
    "        # Проверка полноты разбиения\n",
    "        assert len(X.iloc[train_idxs]) + len(X.iloc[test_idxs]) == len(X) # True\n",
    "\n",
    "    return result_lst\n",
    "\n",
    "\n",
    "my_kfold_cv(df, n_splits=5, shuffle=False,)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fb9d870",
   "metadata": {},
   "source": [
    "#### b. Grouped K-Fold, where k and group_field are input parameters, returns list of train and test indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a59a2baa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(array([    0,     1,     2, ..., 49349, 49350, 49351], shape=(39481,)),\n",
       "  array([   19,    26,    38, ..., 49340, 49344, 49346], shape=(9871,))),\n",
       " (array([    0,     2,     3, ..., 49348, 49349, 49350], shape=(39481,)),\n",
       "  array([    1,     5,     6, ..., 49341, 49342, 49351], shape=(9871,))),\n",
       " (array([    0,     1,     2, ..., 49348, 49350, 49351], shape=(39482,)),\n",
       "  array([    7,     8,    27, ..., 49338, 49345, 49349], shape=(9870,))),\n",
       " (array([    1,     3,     5, ..., 49348, 49349, 49351], shape=(39482,)),\n",
       "  array([    0,     2,     4, ..., 49333, 49343, 49350], shape=(9870,))),\n",
       " (array([    0,     1,     2, ..., 49349, 49350, 49351], shape=(39482,)),\n",
       "  array([    3,     9,    18, ..., 49334, 49347, 49348], shape=(9870,)))]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import GroupKFold\n",
    "\n",
    "gkf = GroupKFold(5)\n",
    "\n",
    "list(gkf.split(df, groups=df[\"building_id\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4573f895",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 4.b\n",
    "def my_group_kfold_cv(X, groups, n_splits=5):\n",
    "    result = []\n",
    "    n = len(X)\n",
    "    groups = np.asarray(groups)\n",
    "    unq_group, inv_idxs, cnt_group = np.unique(groups,\n",
    "                                               return_inverse=True,\n",
    "                                               return_counts=True)\n",
    "    if not len(unq_group) >= n_splits:\n",
    "        raise ValueError(\"There are fewer unique 'groups' than 'n_splits'\")\n",
    "\n",
    "    indices = {}\n",
    "    for i, uid in enumerate(unq_group):\n",
    "        indices[uid] = np.where(inv_idxs == i)[0].tolist()\n",
    "\n",
    "    order = np.argsort(cnt_group)[::-1]\n",
    "    unq_group = unq_group[order]\n",
    "    cnt_group = cnt_group[order]\n",
    "\n",
    "    fold_sizes = np.zeros(n_splits, dtype=int)\n",
    "    group_folds = [[] for _ in range(n_splits)]\n",
    "    for g, c in zip(unq_group, cnt_group):\n",
    "        i = np.argmin(fold_sizes)\n",
    "        group_folds[i].extend(indices[g])\n",
    "        fold_sizes[i] += c\n",
    "\n",
    "    for test_idx in group_folds:\n",
    "        mask = np.ones(n, dtype=bool)\n",
    "        mask[test_idx] = False\n",
    "        train_idx = np.nonzero(mask)[0]\n",
    "        result.append((train_idx, np.array(sorted(test_idx))))\n",
    "\n",
    "    return result\n",
    "\n",
    "\n",
    "for train, test in my_group_kfold_cv(df, df[\"building_id\"], n_splits=5):\n",
    "    display(\n",
    "        '8579a0b0d54db803821a35a4a615e97a' in df.iloc[test][\"building_id\"].values\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71b2b68",
   "metadata": {},
   "source": [
    "#### c. Stratified K-fold, where k and stratify_field are input parameters, returns list of train and test indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8543b251",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d4cd2473",
   "metadata": {},
   "source": [
    "#### d. Time series split, where k and date_field are input parameters, returns list of train and test indices."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23031fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7d7cb6a4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 5. **Cross-validation comparison**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f046e99f",
   "metadata": {},
   "source": [
    "#### a. Apply all the validation methods implemented above to our dataset. To apply Stratified algorithm you should preprocess target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7acfac67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f9f8a7d1",
   "metadata": {},
   "source": [
    "#### b. Apply the appropriate methods from sklearn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f40abe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "df757757",
   "metadata": {},
   "source": [
    "#### c. Compare the resulting feature distributions for the training part of the dataset between sklearn and your implementation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f67d96d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "93c94ddb",
   "metadata": {},
   "source": [
    "#### d. Compare all validation schemes. Choose the best one. Explain your choice."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9aab74",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1686f2ea",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 6. **Feature Selection**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f330f09",
   "metadata": {},
   "source": [
    "#### a. Fit a Lasso regression model with normalized features. Use your method for splitting samples into 3 parts by field created with 60/20/20 ratio — train/validation/test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec4063f0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "aca071d2",
   "metadata": {},
   "source": [
    "#### b. Sort features by weight coefficients from model, fit model to top 10 features and compare quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5158032a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e1262a5d",
   "metadata": {},
   "source": [
    "#### c. Implement method for simple feature selection by nan-ratio in feature and correlation. Apply this method to feature set and take top 10 features, refit model and measure quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a66378",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "29f95f49",
   "metadata": {},
   "source": [
    "#### d. Implement permutation importance method and take top 10 features, refit model and measure quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db5abf40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "87f72988",
   "metadata": {},
   "source": [
    "#### e. Import Shap and also refit model on top 10 features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06d32ad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7de62330",
   "metadata": {},
   "source": [
    "#### f. Compare the quality of these methods for different aspects — speed, metrics and stability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7887a524",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7c86d86e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "### 7. **Hyperparameter optimization**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524151e1",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "source": [
    "#### a. Implement grid search and random search methods for alpha and l1_ratio for sklearn's ElasticNet model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13434909",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e30f5382",
   "metadata": {},
   "source": [
    "#### b. Find the best combination of model hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c89db2dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75b375b0",
   "metadata": {},
   "source": [
    "#### c. Fit the resulting model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ebcfba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4ceeecd2",
   "metadata": {},
   "source": [
    "#### d. Import optuna and configure the same experiment with ElasticNet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb15c6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e7bc879c",
   "metadata": {},
   "source": [
    "#### e. Estimate metrics and compare approaches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3430eb31",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b3eb2aec",
   "metadata": {},
   "source": [
    "#### f. Run optuna on one of the cross-validation schemes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b7b584",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "3.10.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
