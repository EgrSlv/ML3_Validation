# Model quality estimation

Данный проект посвящен различным моделям валидации моделей машинного обучения. Правилам измерения качества моделей для избежания утечек данных. Также рассматривается несколько способов оптимизации гиперпараметров модели и различные методы отбора признаков.

## Contents

1. [Chapter I. Preamble](#chapter-i-preamble)
2. [Chapter II. Introduction](#chapter-ii-introduction) \
    2.1. [One fold validation](#one-fold-validation) \
    2.2. [Cross-validation (N folds validation)](#cross-validation-n-folds-validation) \
    2.3. [Hyperparameter optimization](#hyperparameter-optimization) \
    2.4. [Feature selection](#feature-selection)
3. [Chapter III. Goal](#chapter-iii-goal)
4. [Chapter IV. Instructions](#chapter-iv-instructions)
5. [Chapter V. Task](#chapter-v-task)

## Chapter I. Preamble

В предыдущих проектах мы рассмотрели множество различных примеров применения машинного обучения и углубились в построение моделей линейной регрессии. Но мы всегда готовили обучающие и тестовые выборки. В этом проекте мы обсудим, как разделить набор данных на части, чтобы правильно построить модели.

Процесс валидации, вероятно, является одной из самых сложных и важных частей процесса моделирования. Рассмотрим несколько примеров: представим, что вы — крупная компания розничной торговли продуктами питания. И с начала лета перед вами стоит задача прогнозирования продаж мороженого на следующие 3 месяца. Вы собрали данные за последнее полугодие. В качестве тестового набора вы используете данные за последние три доступных месяца. Но 3 летних месяца, которые мы сейчас не можем наблюдать, 3 весенних месяца и 3 зимних месяца из имеющихся данных будут иметь разный характер. Всем известно, что продажи мороженого снижаются в холодные месяцы.

Рассмотрим более сложный пример. Нам нужно предсказать количество неплатежей по кредитам в банке. Это распространенная задача на практике. Если мы сгруппируем обучающие и тестовые выборки в этой задаче по идентификатору заявки на кредит, мы допустим большую ошибку. Почему? Клиент может обращаться в банк за кредитом несколько раз. И может случиться так, что кредит клиента за 2020 год окажется в обучающей выборке, а кредит того же клиента за 2018 год — в тестовой. Это означает, что обученная модель уже будет знать, что клиент погасил кредит в 2018 году. Конечно, это знание не заложено непосредственно в модель, но весьма вероятно, что эта информация хранится в признаках. Это позволяет модели усваивать вводящие в заблуждение закономерности и приводит к недообучению.
Такая ситуация обычно называется **data leakage** (утечка данных).

И это еще не все. Помните, что в предыдущем проекте мы выбирали специальные признаки для наших моделей? Что, если мы хотим попробовать разные возможные подмножества и выбрать лучшее, которое не содержит избыточных признаков? Или вы могли заметить, что при добавлении регуляризации к функции потерь она включает в себя вес, на который мы умножаем. Этот вес также влияет на производительность модели. Так как же нам ее оптимизировать? Спойлер: для таких целей нам также следует разделить наш набор данных на валидационную часть, то есть на обучающую, валидную и тестовую части.

Таким образом, главная цель процесса валидации — найти наилучший способ организации процессов обучения и тестирования таким образом, чтобы они не вносили ошибок в модель во время её работы в производственной среде. Давайте рассмотрим методы валидации.

## Chapter II. Introduction

### One fold validation

Разделение данных на две части — обучающую и тестовую — кажется очевидной идеей. Но существует множество способов это сделать. Первый и самый простой способ — это случайное разделение по некоторому идентификатору с фиксированным соотношением обучающей и тестовой выборок. Например, случайное разделение по индексу набора данных образцов или по идентификатору пользователя, соответствующему отдельному образцу в нашем наборе данных. Это широко используемый метод в случаях, когда у вас много данных и **данные не имеют временной зависимости**. В этом случае тестовая часть часто называется **`out-of-fold`** (внекорневая). Здесь «корневая» — синоним «части набора данных». Таким образом, «внекорневая» означает, что мы проверяем производительность на образцах, которые не входят в часть, используемую для обучения.

Второй способ разделить набор данных на две выборки — отсортировать данные по времени или дате и взять какой-нибудь из последних периодов в качестве тестового. Будьте осторожны с приведенным выше примером. Очевидно, этот метод можно использовать, если в данных присутствуют временные зависимости. В этом случае наш метод разделения называется **`out-of-time`**.

На практике двух фолдов — обучающего и тестового — недостаточно. Далее в этой главе мы рассмотрим части конвейера моделирования, такие как выбор признаков и оптимизация гиперпараметров, которые требуют специального фолда для оценки качества модели, и этот набор называется **`validation set`**. Это может быть фолд, созданный из обучающего набора с использованием стратегии **`out-of-fold`** или **`out-of-time`**.

Важно отметить, что:
* На обучающей части набора данных мы обучаем нашу модель.
* На валидационной части набора данных мы измеряем качество обученной модели и настраиваем ее производительность, изменяя различные условия предварительно обработанных данных или изменяя гиперпараметры модели.
* На тестовой части набора данных мы измеряем конечное качество нашей модели, чтобы понять реальную пользу от нашей модели.

Таким образом, вы не можете использовать тестовые данные в процессе моделирования, за исключением конечного измерения метрики.

Ниже мы визуализируем процесс разделения на обучающую, валидационную и тестовую выборки.

<p align="center">
    <img src="./misc/images/classic_approach.png" width="560"/><br/>
    <strong>1. Classic approach</strong> (out-of-fold)
    <br/><br/>
    <br/><br/>
    <img src="./misc/images/out_of_time_for_test_part.png" width="600"/><br/>
    <strong>2. Out-of-time</strong> for test part
    <br/><br/>
    <br/><br/>
    <img src="./misc/images/out_of_time_both_and_valid_parts.png" width="640"/><br/>
    <strong>3. Out-of-time</strong> for test and valid parts
    <br/><br/>
    <br/><br/>
</p>

Источник: https://muse.union.edu/dvorakt/train-validate-and-test-with-time-series/

Как мы видим выше, мы можем комбинировать эти методы. Но что делать, если у нас не так много данных для моделирования, как избежать переобучения?

### Cross-validation (N Fold Validation)

На практике мы можем столкнуться со многими проблемами, где нам не удается собрать достаточно данных для обучения модели, например, с медицинскими проблемами, где сбор данных является дорогостоящим и сложным процессом.

В таких случаях можно использовать **`cross-validation`**. Сначала мы разбиваем данные на N-fold частей. Затем берем первый fold и используем его в качестве тестового, а остальные фолды используем для обучения модели. После этого повторяем этот процесс для следующего fold и так далее. Наконец, необходимо собрать метрики со всех фолдов и вычислить среднее значение для оценки производительности модели. Наиболее распространенное количество folds находится в диапазоне от 3 до 10.

Для более подробного понимания см. рисунок ниже:

<p align="center">
    <img src="./misc/images/grid_search_cross_validation.png" width="720"/><br/>
    <strong>Cross-validation</strong>
    <br/><br/>
</p>

Источник: https://scikit-learn.org/stable/modules/cross_validation.html

Существует частный случай кросс-валидации, называемый **`leave-one-out validation scheme`** (кросс-валидация методом "оставь одного"). Вам предстоит найти определение этой схемы, а также указать ее ограничения и сильные стороны.

В библиотеке sklearn существует несколько специальных методов кросс-валидации:
 * **K-fold**
 * **group K-fold**
 * **stratified K-fold**
 * **TimeSeriesSplit**

 Давайте рассмотрим их подробнее, чтобы понять различия.

<p align="center">
    <img src="./misc/images/k_fold.png" width="720"/><br/>
    <strong>K-Fold</strong>
    <br/><br/>
</p>

**K-Fold** повторяет описанное выше. **<font color="blue">Синий цвет</font>** обозначает обучающий набор данных, а **<font color="red">красный</font>** — тестовый. Для оценки производительности мы обучаем и оцениваем нашу модель на 4 различных разбиениях, а затем берем средний балл. В качестве альтернативы, для каждого красного фрагмента мы можем запомнить предсказание соответствующей модели. Если мы объединим эти предсказания, мы получим вектор, называемый **`out-of-fold predictions`**. Таким образом, мы можем вычислить нашу метрику производительности, передав **`out-of-fold predictions`** и истинные метки в функцию.

Почему мы упоминаем эту альтернативу? Потому что метод `out-of-fold` может быть полезен для повышения производительности модели, но эта тема выходит за рамки данного проекта. Если вы хотите углубиться в тему, **почитайте о методе stacking**.

K-Fold метод имеет существенный недостаток, когда данные содержат наблюдения общей группы. В данном случае группой может быть любое важное свойство, на которое, по вашему мнению, следует разделить данные. Это могут быть наблюдения за клиентом в разное время или идентификаторы разных самолетов, где необходимо выявить разрывы. В таких случаях необходимо разделить обучающую и тестовую выборки на части таким образом, чтобы клиент/самолет присутствовал только в обучающей или тестовой выборке — это не могут быть пересечения идентификаторов клиентов в обучающей и тестовой выборках.

Этот метод называется **Group K-Fold**. Как и прежде, мы разделили нашу выборку на K-Folds, но и также группируем её по специальному параметру. Ниже вы можете увидеть визуализацию **group K-Fold** по столбцу "group".

<p align="center">
    <img src="./misc/images/group_k_fold.png" width="920"/><br/>
    <strong>Group K-Fold</strong>
    <br/><br/>
</p>

Существует еще несколько интересных и важных направлений в кросс-валидации. Они называются **`Stratified K-fold`** и **`Stratified Group K-fold`**. Ваша задача — привести несколько примеров, где необходимо стратифицировать целевые переменные по фолдам. Опишите сильные и слабые стороны этих методов.

Теперь рассмотрим последнюю схему кросс-валидации, когда данные имеют временную зависимость. Она называется **`TimeSeriesSplit`** (разделение временных рядов). Прежде всего, нам нужно отсортировать наши данные по дате или указанному временному периоду. Определим k — это будет количество разделений.

<p align="center">
    <img src="./misc/images/time_series_split.png" width="920"/><br/>
    <strong>TimeSeriesSplit</strong>
    <br/><br/>
</p>

Для первой модели мы берем 1/k данных для обучающей выборки, а затем 1/k для тестовой выборки. Для второй модели мы расширяем обучающую выборку до 2/k данных и перемещаем скользящее окно на следующий 1/k для тестовой выборки. И так далее. В этом методе мы обучаем k-1 моделей вместо k моделей.

### Hyperparameter optimization

В этой части мы обсудим оптимизацию гиперпараметров — процесс поиска наилучшей комбинации параметров модели для повышения производительности и уменьшения переобучения. Существует два типа параметров модели: **`internal`** (внутренние) — модель оптимизирует эти параметры самостоятельно во время подгонки, и **`external`** (внешние) — которые не обновляются во время подгонки (мы не обновляем их с помощью градиента или каким-либо другим способом). Такие внешние параметры называются **`hyperparameters`** (гиперпараметрами), и здесь мы будем говорить только о них. Попробуйте привести несколько примеров для обоих типов параметров.

Оптимизация гиперпараметров — это циклический процесс. Вы изменяете один или несколько параметров модели, обучаете модель на обучающем наборе данных и измеряете качество на валидационном наборе данных. Если показатели улучшаются, вы продолжаете в этом направлении, а если нет, то пытаетесь их изменить.

Иногда здравый смысл помогает выбрать подходящие гиперпараметры для оптимизации. Например, предположим, что в качестве базового алгоритма используется полиномиальная регрессия. И мы видим большой разрыв между метриками на обучающем и валидационном наборах данных. Таким образом, мы делаем вывод, что наша модель переобучена. Здравый смысл подсказывает нам уменьшить количество полиномиальных признаков — в данном случае их число является гиперпараметром. Но как найти оптимальный набор из 5 или 10 независимых гиперпараметров?

К сожалению, практически нет ничего лучше, чем проверить все значимые комбинации гиперпараметров. Этот метод называется **`Grid Search`** (поиск по сетке). Но он занимает много времени. Если у нас ограниченное количество времени, мы можем использовать **`Randomized Grid Search`** (случайный поиск по сетке). Понимание принципов их работы является частью вашего задания.

Однако у обоих этих подходов есть недостаток — они не учитывают взаимосвязи параметров. Если мы построим 3 модели с одинаковой степенью полиномиальных характеристик, изменим другие гиперпараметры и получим плохие результаты? Насколько вероятно, что нам следует попробовать другую степень? Идея, решающая эту проблему, применяется в Байесовской оптимизации.

В Python есть две библиотеки, реализующие это решение: **`hyperopt`** и **`optuna`** (optuna кажется лучше). Объяснение математических основ этого подхода также входит в вашу задачу.

### Feature selection

Следующий важный шаг в процессе моделирования, который также можно рассматривать как оптимизацию гиперпараметров, — это отбор признаков. Часто у нас есть тысячи признаков из исходных источников данных, и мы также можем генерировать их в огромном количестве. Очевиден вопрос, как найти наиболее важные признаки, обладающие сигналом, и удалить зашумленные и ненужные столбцы. В результате мы можем не только ускорить модель, но и повысить ее производительность. Но как это сделать?

Как и в случае с гиперпараметрами, мы могли бы перебрать все возможные комбинации признаков и найти оптимум, но это займет слишком много времени. К счастью, по сравнению с настройкой гиперпараметров существует множество подходов к выбору признаков. Чтобы понять их все, лучше использовать некоторую классификацию:

<p align="center">
    <img src="./misc/images/feature_selection_methods.webp" width="720"/><br/>
    <strong>Feature Selection Methods</strong>
    <br/><br/>
</p>

Источник: https://neptune.ai/blog/feature-selection-methods (этот список неполный, и классификация может быть не совсем точной).

Разделение на контролируемое и неконтролируемое (с учителем / без учителя) обучение такое же, как и в задачах машинного обучения. Понять разницу между обертками (wrapers), фильтрами (filters) и встраиванием (embedded) - ваша задача в этом проекте. Пожалуйста, убедитесь, что вы знакомы со следующими методами:
* Все методы обучения без учителя;
* Все методы оберток;
* Фильтры:
  * Pearson,
  * Chi2;
* Встраивание:
  * Lasso,
  * Ridge.
* Следующие методы находятся где-то между обертками и фильтрами и не показаны на рисунке выше. Но эти методы очень рекомендуются:
  * **permutation importance** (важность перестановок);
  * **shap** — https://shap.readthedocs.io/en/latest/.

В заключение, перед началом практики, хотим отметить, что оптимизацию гиперпараметров и отбор признаков можно сочетать с кросс-валидацией. Это поможет сделать эти процессы справедливыми и предотвратить переобучение моделей.

## Глава III. Цель

Цель данного задания — получить глубокое понимание схем валидации, оптимизации гиперпараметров и отбора признаков.

## Chapter IV. Instructions

* Этот проект будет оцениваться только людьми. Вы можете организовывать и называть файлы по своему усмотрению.
* Здесь и в дальнейшем мы используем Python 3 как единственно правильную версию Python.
* Для обучения алгоритмов глубокого обучения вы можете попробовать [Google Colab](https://colab.research.google.com). Он предлагает бесплатные ядра (среду выполнения) с GPU, которые быстрее, чем CPU, для таких задач.
* Стандарт не применяется к этому проекту. Однако вас просят быть ясными и структурированными в проектировании исходного кода.
* Сохраняйте наборы данных в подпапке data.

## Chapter V. Task

Мы продолжим обучение на задаче с сайта Kaggle.com.
В этой главе мы реализуем все описанные выше схемы валидации, некоторые методы настройки гиперпараметров и методы отбора признаков. Измерим метрики качества на обучающих и тестовых выборках. Выявим переобученные модели и выполним регуляризацию. И углубимся в нативную оценку и сравнение моделей.
1. Ответьте на вопросы из введения.
    1. Что такое метод «исключения одного элемента»? Укажите его ограничения и преимущества.
    2. Как работают методы Grid Search, Randomized Grid Search и Bayesian optimization?
    3. Объясните классификацию методов выбора признаков. Объясните, как работают коэффициенты Пирсона и Chi2. Объясните, как работает метод Lasso. Объясните, что такое значимость перестановок. Ознакомьтесь с SHAP.

2. Введение — выполните всю предварительную обработку данных из предыдущего урока
    1. Прочитайте все данные.
    2. Создайте признаки: «Лифт», «Паркетные полы», «Разрешено содержание кошек», «Разрешено содержание собак», «Швейцар», «Посудомоечная машина», «Без платы», «Прачечная в здании», «Фитнес-центр», «Довоенный», «Прачечная в квартире», «Крыша», «Открытое пространство», «Столовая», «Высокоскоростной интернет», «Балкон», «Бассейн», «Прачечная в здании», «Новое строительство», «Терраса».

3. Реализуйте следующие методы:
    1. Случайным образом разделите данные на 2 части с параметром test_size (отношение от 0 до 1), верните обучающую и тестовую выборки.
    2. Случайным образом разделите данные на 3 части с параметрами validation_size и test_size, верните обучающую, валидационную и тестовую выборки.
    3. Разделите данные на 2 части с параметром date_split, верните обучающую и тестовую выборки, разделенные по параметру date_split.
    4. Разделите данные на 3 части с параметрами validation_date и test_date, верните обучающую, валидационную и тестовую выборки, разделенные по входным параметрам.
    5. Сделайте процедуру разделения детерминированной. Что это значит?

4. Реализуйте следующие методы перекрестной проверки:
    1. K-кратная проверка (K-Fold), где k — входной параметр, возвращает список индексов обучающей и тестовой выборок.
    2. Группированная K-кратная проверка (Grouped K-Fold), где k и group_field — входные параметры, возвращает список индексов обучающей и тестовой выборок.
    3. Стратифицированная K-кратная проверка (Stratified K-fold), где k и stratify_field — входные параметры, возвращает список индексов обучающей и тестовой выборок.
    4. Разделение временных рядов (Time series split), где k и date_field — входные параметры, возвращает список индексов обучающей и тестовой выборок.

5. Сравнительный анализ перекрестной проверки
    1. Примените все описанные выше методы проверки к нашему набору данных. Для применения алгоритма стратификации необходимо предварительно обработать целевые данные.
    2. Примените соответствующие методы из библиотеки sklearn.
    3. Сравните результирующие распределения признаков для обучающей части набора данных между sklearn и вашей реализацией.
    4. Сравните все схемы проверки. Выберите лучшую. Объясните свой выбор.

6. Выбор признаков
    1. Постройте модель регрессии Lasso с нормализованными признаками. Используйте свой метод разделения выборок на 3 части по полям, созданным в соотношении 60/20/20 — обучающая/валидационная/тестовая выборки.
    2. Отсортируйте признаки по весовым коэффициентам модели, постройте модель на основе 10 лучших признаков и сравните их качество.
    3. Реализуйте метод простого выбора признаков по соотношению NaN в признаках и корреляции. Примените этот метод к набору признаков, выберите 10 лучших признаков, перестройте модель и оцените качество.
    4. Реализуйте метод пермутационной важности, выберите 10 лучших признаков, перестройте модель и оцените качество.
    5. Импортируйте Shap и также перестройте модель на основе 10 лучших признаков.
    6. Сравните качество этих методов по различным параметрам — скорости, метрикам и стабильности.

7. Оптимизация гиперпараметров
    1. Реализуйте методы поиска по сетке и случайного поиска для параметров alpha и l1_ratio для модели ElasticNet из библиотеки sklearn.
    2. Найдите наилучшую комбинацию гиперпараметров модели.
    3. Обучите полученную модель.
    4. Импортируйте optuna и настройте тот же эксперимент с ElasticNet.
    5. Оцените метрики и сравните подходы.
    6. Запустите optuna на одной из схем перекрестной проверки.
